Setting up Training Environment...
Creating Liquid PPO Agent...
Using cpu device
Wrapping the env with a `Monitor` wrapper
Wrapping the env in a DummyVecEnv.
Starting Training (This may take a while)...
----------------------------------
| rollout/           |           |
|    ep_len_mean     | 1e+03     |
|    ep_rew_mean     | -1.79e+04 |
| time/              |           |
|    fps             | 465       |
|    iterations      | 1         |
|    time_elapsed    | 4         |
|    total_timesteps | 2048      |
----------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -1.91e+04   |
| time/                   |             |
|    fps                  | 24          |
|    iterations           | 2           |
|    time_elapsed         | 169         |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.004881427 |
|    clip_fraction        | 0.0184      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.67       |
|    explained_variance   | 0.000221    |
|    learning_rate        | 0.0003      |
|    loss                 | 4.46e+04    |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00155    |
|    std                  | 0.998       |
|    value_loss           | 9.86e+04    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.01e+04    |
| time/                   |              |
|    fps                  | 31           |
|    iterations           | 3            |
|    time_elapsed         | 196          |
|    total_timesteps      | 6144         |
| train/                  |              |
|    approx_kl            | 0.0020806824 |
|    clip_fraction        | 0.00215      |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.66        |
|    explained_variance   | -6.6e-05     |
|    learning_rate        | 0.0003       |
|    loss                 | 6.96e+04     |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.000315    |
|    std                  | 0.996        |
|    value_loss           | 1.37e+05     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.08e+04    |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 4            |
|    time_elapsed         | 226          |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0041169263 |
|    clip_fraction        | 0.0206       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.66        |
|    explained_variance   | -5.96e-06    |
|    learning_rate        | 0.0003       |
|    loss                 | 7.12e+04     |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00234     |
|    std                  | 0.994        |
|    value_loss           | 1.63e+05     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -2.1e+04    |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 5           |
|    time_elapsed         | 242         |
|    total_timesteps      | 10240       |
| train/                  |             |
|    approx_kl            | 0.003560378 |
|    clip_fraction        | 0.0138      |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.66       |
|    explained_variance   | 6.62e-06    |
|    learning_rate        | 0.0003      |
|    loss                 | 8.45e+04    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00122    |
|    std                  | 0.998       |
|    value_loss           | 1.94e+05    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.13e+04    |
| time/                   |              |
|    fps                  | 47           |
|    iterations           | 6            |
|    time_elapsed         | 258          |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0027945049 |
|    clip_fraction        | 0.0139       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.67        |
|    explained_variance   | 2.8e-06      |
|    learning_rate        | 0.0003       |
|    loss                 | 6.45e+04     |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00151     |
|    std                  | 1            |
|    value_loss           | 1.47e+05     |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 1e+03       |
|    ep_rew_mean          | -2.19e+04   |
| time/                   |             |
|    fps                  | 52          |
|    iterations           | 7           |
|    time_elapsed         | 274         |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.004093081 |
|    clip_fraction        | 0.018       |
|    clip_range           | 0.2         |
|    entropy_loss         | -5.68       |
|    explained_variance   | 1.79e-07    |
|    learning_rate        | 0.0003      |
|    loss                 | 9.83e+04    |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00117    |
|    std                  | 1           |
|    value_loss           | 1.69e+05    |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.21e+04    |
| time/                   |              |
|    fps                  | 56           |
|    iterations           | 8            |
|    time_elapsed         | 290          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0041737873 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.67        |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.0003       |
|    loss                 | 9.31e+04     |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.00342     |
|    std                  | 0.996        |
|    value_loss           | 1.76e+05     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.21e+04    |
| time/                   |              |
|    fps                  | 59           |
|    iterations           | 9            |
|    time_elapsed         | 309          |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0060277004 |
|    clip_fraction        | 0.037        |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.65        |
|    explained_variance   | 2.21e-06     |
|    learning_rate        | 0.0003       |
|    loss                 | 6.73e+04     |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00309     |
|    std                  | 0.991        |
|    value_loss           | 1.55e+05     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.32e+04    |
| time/                   |              |
|    fps                  | 62           |
|    iterations           | 10           |
|    time_elapsed         | 326          |
|    total_timesteps      | 20480        |
| train/                  |              |
|    approx_kl            | 0.0032014307 |
|    clip_fraction        | 0.0083       |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.63        |
|    explained_variance   | 2.98e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 8.79e+04     |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.000593    |
|    std                  | 0.989        |
|    value_loss           | 1.53e+05     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.57e+04    |
| time/                   |              |
|    fps                  | 64           |
|    iterations           | 11           |
|    time_elapsed         | 348          |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0035356751 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.61        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0003       |
|    loss                 | 1.91e+05     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.981        |
|    value_loss           | 3.78e+05     |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 1e+03        |
|    ep_rew_mean          | -2.78e+04    |
| time/                   |              |
|    fps                  | 67           |
|    iterations           | 12           |
|    time_elapsed         | 365          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0027306664 |
|    clip_fraction        | 0.00293      |
|    clip_range           | 0.2          |
|    entropy_loss         | -5.6         |
|    explained_variance   | 1.79e-07     |
|    learning_rate        | 0.0003       |
|    loss                 | 4.31e+05     |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.000544    |
|    std                  | 0.983        |
|    value_loss           | 9.15e+05     |
------------------------------------------
Traceback (most recent call last):
  File "/home/ylop/Documents/drone go brr/Drone-go-brrrrr/Drone-go-brrrrr/train.py", line 35, in <module>
    train()
    ~~~~~^^
  File "/home/ylop/Documents/drone go brr/Drone-go-brrrrr/Drone-go-brrrrr/train.py", line 28, in train
    model.learn(total_timesteps=total_timesteps, callback=checkpoint_callback)
    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/stable_baselines3/ppo/ppo.py", line 311, in learn
    return super().learn(
           ~~~~~~~~~~~~~^
        total_timesteps=total_timesteps,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        progress_bar=progress_bar,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/ylop/.local/lib/python3.14/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 324, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/ylop/.local/lib/python3.14/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 202, in collect_rollouts
    actions, values, log_probs = self.policy(obs_tensor)
                                 ~~~~~~~~~~~^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ylop/.local/lib/python3.14/site-packages/stable_baselines3/common/policies.py", line 645, in forward
    features = self.extract_features(obs)
  File "/home/ylop/.local/lib/python3.14/site-packages/stable_baselines3/common/policies.py", line 672, in extract_features
    return super().extract_features(obs, self.features_extractor if features_extractor is None else features_extractor)
           ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/stable_baselines3/common/policies.py", line 131, in extract_features
    return features_extractor(preprocessed_obs)
  File "/home/ylop/.local/lib/python3.14/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ylop/Documents/drone go brr/Drone-go-brrrrr/Drone-go-brrrrr/models/liquid_ppo.py", line 58, in forward
    output, self.hx = self.ltc(observations, self.hx)
                      ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/torch/nn/modules/module.py", line 1775, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/torch/nn/modules/module.py", line 1786, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/ylop/.local/lib/python3.14/site-packages/ncps/torch/ltc.py", line 185, in forward
    h_out, h_state = self.rnn_cell.forward(inputs, h_state, ts)
                     ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
  File "/home/ylop/.local/lib/python3.14/site-packages/ncps/torch/ltc_cell.py", line 282, in forward
    next_state = self._ode_solver(inputs, states, elapsed_time)
  File "/home/ylop/.local/lib/python3.14/site-packages/ncps/torch/ltc_cell.py", line 247, in _ode_solver
    v_pre = numerator / (denominator + self._epsilon)
    ^^^^^
KeyboardInterrupt
